{"content": "div#hs-eu-cookie-confirmation{background:#fff;height:auto;left:0;position:absolute;top:0;width:100%;z-index:100000000!important;border-bottom:1px solid #cbd6e2;border-top:1px solid #cbd6e2;box-shadow:0 1px 5px #eaf0f6;color:#33475b;font-family:inherit;font-size:inherit;font-weight:400!important;line-height:inherit;text-align:left;text-shadow:none!important;font-size:12px;font-family:Helvetica Neue,Helvetica,Arial,sans-serif;line-height:18px}div#hs-eu-cookie-confirmation.hs-cookie-notification-position-bottom{position:fixed;border-bottom:0;bottom:0;top:auto;box-shadow:0 -1px 3px #eaf0f6}div#hs-eu-cookie-confirmation *{box-sizing:border-box!important}div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner{background:#fff;margin:0 auto;max-width:1000px;padding:20px}div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner a{text-decoration:none!important}div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner a,div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner a:hover{background:none!important;border:none!important;box-shadow:none!important;color:#0091ae;font-family:inherit;font-size:inherit;font-weight:400!important;line-height:inherit;text-align:left;text-shadow:none!important}div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner a:hover{text-decoration:underline!important}div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner div#hs-eu-policy-wording{margin-bottom:12px}div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner div#hs-en-cookie-confirmation-buttons-area,div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner div#hs-eu-cookie-confirmation-button-group{display:flex;flex-direction:row;flex-wrap:wrap;align-items:center}div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner div#hs-en-cookie-confirmation-buttons-area{margin-right:72px;justify-content:flex-end;align-items:center}@media (max-width:800px){div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner div#hs-en-cookie-confirmation-buttons-area{justify-content:center;margin-right:0}}div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner div#hs-eu-cookie-confirmation-button-group{justify-content:center}div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner a#hs-eu-confirmation-button,div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner a#hs-eu-cookie-settings-button,div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner a#hs-eu-decline-button{margin:6px!important}div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner a#hs-eu-confirmation-button,div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner a#hs-eu-decline-button{border-radius:3px;display:inline-block;padding:10px 16px!important;text-decoration:none!important}div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner a#hs-eu-confirmation-button{background-color:#425b76!important;border:1px solid #425b76!important;color:#fff;font-family:inherit;font-size:inherit;font-weight:400!important;line-height:inherit;text-align:left;text-shadow:none!important}div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner a#hs-eu-decline-button{border:1px solid #425b76!important;color:#425b76;font-family:inherit;font-size:inherit;font-weight:400!important;line-height:inherit;text-align:left;text-shadow:none!important}div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner a#hs-eu-cookie-settings-button{color:#425b76!important}div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner p{margin:0 72px 12px;color:#33475b;font-family:inherit;font-size:inherit;font-weight:400!important;line-height:inherit;text-align:left;text-shadow:none!important}@media (max-width:800px){div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner p{margin:0 20px 12px}}#hs-eu-close-button-container{display:flex;justify-content:end;margin-top:8px;margin-right:8px}#hs-eu-close-button-container a#hs-eu-close-button[role=button]{float:right;width:1.5rem;font-size:40px!important;text-align:center!important;cursor:pointer;color:#8b8589!important}#hs-eu-close-button-container a#hs-eu-close-button[role=button]:hover{background:none!important;border:none!important;box-shadow:none!important;color:#0091ae;font-family:inherit;font-size:inherit;font-weight:400!important;line-height:inherit;text-align:left;text-shadow:none!important;text-decoration:none!important}@media (max-width:800px){#hs-eu-close-button-container a#hs-eu-close-button[role=button]{margin-right:10px;font-size:30px;line-height:50px}}@media (min-width:800px){#hs-eu-close-button-container a#hs-eu-close-button[role=button]{margin-bottom:10px}}@media print{div#hs-eu-cookie-confirmation{display:none!important}}@media screen and (max-width:480px){div#hs-eu-cookie-confirmation{font-size:12px!important}div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner{padding:8px 14px 14px!important}div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner a,div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner a#hs-eu-confirmation-button{font-size:12px!important}div#hs-eu-cookie-confirmation div#hs-eu-cookie-confirmation-inner p{font-size:12px!important;margin-bottom:12px!important;line-height:15px!important}}@media only screen and (min-width:960px){div#hs-eu-cookie-confirmation{position:fixed}}\n            \n              \n              This website stores cookies on your computer. These cookies are used to improve your website experience and provide more personalized services to you, both on this website and through other media. To find out more about the cookies we use, see our Privacy Policy.\n              We won't track your information when you visit our site. But in order to comply with your preferences, we'll have to use just one tiny cookie so that you're not asked to make this choice again.\n              \n                \n                \n                \n    Accept\n  \n                Decline\n                \n              \n            \n          \n    \n    \n\n\n\n\n    <iframe src=\"https://www.googletagmanager.com/ns.html?id=GTM-WCKQG9T\" height=\"0\" width=\"0\" style=\"display:none;visibility:hidden\"></iframe>\n\n\n    \n    \n\n\n\n\n\n\n  \n\n\n\n  \n    \n  \n  \n  \n  \n\n\n\n    \n    \n      \n        \n      \n    \n\n    \n    \n\n  \n    \n      \n    \n  \n  \n    \n    \n    \n      \n        \n          \n            Overview\n          \n          \n            \n              \n                What is Haystack?\n              \n            \n              \n                Quick Start\n              \n            \n              \n                Use Cases\n              \n            \n              \n                Demo\n              \n            \n              \n                Roadmap\n              \n            \n          \n        \n      \n    \n    \n      \n      \n        \n          Documentation\n        \n      \n    \n    \n      \n      \n        \n          Tutorials\n        \n      \n    \n    \n      \n      \n        \n          Community\n        \n      \n    \n    \n      \n        \n          \n            Resources\n          \n          \n            \n              \n                Blog\n              \n            \n              \n                Benchmarks\n              \n            \n              \n                Annotation Tool\n              \n            \n              \n                NLP Resources\n              \n            \n          \n        \n      \n    \n\n    \n    \n  \n    \n      \n        \n      \n      \n        Get Started\n      \n      \n        \n      \n    \n  \n\n\n\n\n\n  \n\n\n    \n\n  \n    \n    \n      \n      \n        \n          \n          \n            \n          \n            \n          \n            \n          \n            \n          \n            \n          \n\n          \n            Overview\n          \n\n          \n            \n              \n                \n                  \n                    \n                      \n                    \n                    \n                      What is Haystack?\n                    \n                  \n                \n              \n            \n              \n                \n                  \n                    \n                      \n                    \n                    \n                      Quick Start\n                    \n                  \n                \n              \n            \n              \n                \n                  \n                    \n                      \n                    \n                    \n                      Use Cases\n                    \n                  \n                \n              \n            \n              \n                \n                  \n                    \n                      \n                    \n                    \n                      Demo\n                    \n                  \n                \n              \n            \n              \n                \n                  \n                    \n                      \n                    \n                    \n                      Roadmap\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n      \n      \n        \n        \n          Documentation\n        \n      \n    \n      \n      \n        \n        \n          Tutorials\n        \n      \n    \n      \n      \n        \n        \n          Community\n        \n      \n    \n      \n      \n        \n          \n          \n            \n          \n            \n          \n            \n          \n            \n          \n\n          \n            Resources\n          \n\n          \n            \n              \n                \n                  \n                    \n                      \n                    \n                    \n                      Blog\n                    \n                  \n                \n              \n            \n              \n                \n                  \n                    \n                      \n                    \n                    \n                      Benchmarks\n                    \n                  \n                \n              \n            \n              \n                \n                  \n                    \n                      \n                    \n                    \n                      Annotation Tool\n                    \n                  \n                \n              \n            \n              \n                \n                  \n                    \n                      \n                    \n                    \n                      NLP Resources\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n\n    \n    \n  \n    \n      \n        \n      \n      \n        Get Started\n      \n      \n        \n      \n    \n  \n\n\n\n\n  \n\n\n\n  \n\nvar config={cookieless:!1};!function(b,e,a,f,c,d){b[a]=b[a]||function(){(b[a].q=b[a].q||[]).push(arguments)};b[a].l=1*new Date;c=e.createElement(f);c.async=!0;d=e.getElementsByTagName(f)[0];c.src=\"https://serve.nrich.ai/tracker/assets/tracker.js?nto\\x3d\"+a;d.parentNode.insertBefore(c,d)}(window,document,\"nt\",\"script\");nt(\"load\",\"ee21216a-7b9b-4e72-afbe-5fb9c0448bcd\",config);\n\n\n    \n    \n  \n  \n\n  \n  \n  \n  \n\n\n  \n    \n      \n          \n          \n          Haystack Benchmarks\n\n          \n          \n            \n\n            \n              \n            \n              \n            \n              \n            \n              \n            \n              \n            \n              \n            \n              \n            \n\n          \n                v1.9.0\n              \n                v0.10.0\n              \n                v0.9.0\n              \n                v0.8.0\n              \n                v0.7.0\n              \n                v0.6.0\n              \n                v0.5.0\n              \n          \n        \n\n        \n        Reader Performance\n        Performance benchmarks of different Readers that can be used off-the-shelf in Haystack. Some models are geared towards speed, while others are more performance-focused. Accuracy is measured as F1 score and speed as passages/sec (with passages of 384 tokens).  Each Reader is benchmarked using the SQuAD v2.0 development set, which contains 11866 question answer pairs. When tokenized using the BERT tokenizer and split using a sliding window approach, these become 12350 passages that are passed into the model. We set max_seq_len=384 and doc_stride=128. These benchmarking tests are run using an AWS p3.2xlarge instance with a Nvidia V100 GPU with this script. Please note that we are using the FARMReader class rather than the TransformersReader class. Also, the F1 measure that is reported here is in fact calculated on token level, rather than word level as is done in the official SQuAD script.\n        F1Speed (passages/sec)050100150200250RoBERTaMiniLMBERT baseRoBERTa largeRoBERTa distilleddistilBERTModelF1Speed (passages/sec)RoBERTa78.215118.419MiniLM79.648235.026BERT base73.498116.998RoBERTa large87.3543.454RoBERTa distilled82.294118.881distilBERT43.34198.45Speed (passages/sec)\n\n        \n        Retriever Performance\n        Comparison of the speed and accuracy of different DocumentStore / Retriever combinations on 100k documents. Indexing speed (in docs/sec) refers to how quickly Documents can be inserted into a DocumentStore. Querying speed (in queries/sec) refers to the speed at which the system returns relevant Documents when presented with a query.\n\nThe dataset used is Wikipedia, split into 100 word passages (from here)). \n\nFor querying, we use the Natural Questions development set in combination with the wiki passages. The Document Store is populated with the 100 word passages in which the answer spans occur (i.e. gold passages) as well as a random selection of 100 word passages in which the answer spans do not occur (i.e. negative passages). We take a total of 100k gold and negative passages. Query and document embedding are generated by the \"facebook/dpr-question_encoder-single-nq-base\" and \"facebook/dpr-ctx_encoder-single-nq-base\" models. The retriever returns 10 candidates and both the recall and mAP scores are calculated on these 10.\n\nFor FAISS HNSW, we use n_links=128, efSearch=20 and efConstruction=80. We use a cosine similarity function with BM25 retrievers, and dot product with DPR. Both index and query benchmarks are performed on an AWS P3.2xlarge instance which is accelerated by an Nvidia V100 GPU.\n        mAPIndex Speed (docs/sec)Query Speed (queries/\u20260100200300400500DPR / ElasticsearchBM25 / ElasticsearchSentenceTransformers /ElasticsearchDPR / FAISS (flat)DPR / FAISS (HNSW)BM25 / OpenSearch(flat)DPR / OpenSearch(flat)DPR / OpenSearch(HNSW)ModelmAPIndex Speed (docs/sec)Query Speed (queries/sec)DPR / Elasticsearch86.54681.256.239BM25 / Elasticsearch56.261483.47132.026Sentence Transformers / Elasticsearch82.747120.2416.358DPR / FAISS (flat)86.54693.5916.701DPR / FAISS (HNSW)84.33483.61940.658BM25 / OpenSearch (flat)56.261478.713120.125DPR / OpenSearch (flat)86.51980.32117.604DPR / OpenSearch (HNSW)86.53780.45317.227Query Speed (queries/s\u2026\n\n        \n        Retriever Accuracy\n        Here you can see how the mean avg. precision (mAP) of the retriever decays as the number of documents increases. The set up is the same as the above querying benchmark except that a varying number of negative documents are used to fill the document store.\n        BM25 / ElasticsearchDPR / Elasticsearch1/4100,000200,000300,000400,000500,000020406080100Number of docsmAPn_docsBM25 / ElasticsearchDPR / ElasticsearchDPR / FAISS (flat)DPR / FAISS (HNSW)BM25 / OpenSearch (flat)DPR / OpenSearch (flat)DPR / OpenSearch (HNSW)Sentence Transformers / Elasticsearch1,00074.20492.95192.95192.95174.20492.95192.95190.06610,00066.32989.87189.87189.51366.32989.87189.87187.113100,00056.26186.54686.54684.33456.26186.51986.53782.747500,00045.60480.86180.86175.73345.59580.86180.86176.496Sentence Transformers\u2026\n\n        \n        Retriever Speed\n        Here you can see how the query speed of different Retriever / DocumentStore combinations scale as the number of documents increases. The set up is the same as the above querying benchmark except that a varying number of negative documents are used to fill the document store.\n        BM25 / ElasticsearchBM25 / OpenSearch (flat)1/4100,000200,000300,000400,000500,000050100150200250300Number of docsQueries/secn_docsBM25 / ElasticsearchBM25 / OpenSearch (flat)DPR / ElasticsearchDPR / FAISS (flat)DPR / FAISS (HNSW)DPR / OpenSearch (HNSW)DPR / OpenSearch (HNSW)Sentence Transformers / Elasticsearch1,000258.125174.37336.06335.4941.53835.67335.67348.17610,000196.51173.82325.07631.06450.01330.98730.98730.078100,000132.026120.1256.2396.70140.65817.22717.2276.358500,00067.45967.5931.4681.5345.09811.80911.8091.442Sentence Transformer\u2026\n      \n    \n  \n\n  \n  \n\n  \n  \n\n      \n      function sortSelectMenu() {\n        const selectOptions = Array.from(document.querySelectorAll(\"[data-version]\"))\n        const sorted = selectOptions.sort(compare)\n        sorted.forEach(e => document.querySelector(\"#select-menu\").appendChild(e))\n      }\n\n      function compare(a, b) {\n        const aa = a.dataset.version.split('.').map( n => +n+100000 ).join('.')\n        const bb = b.dataset.version.split('.').map( n => +n+100000 ).join('.')\n        if (aa < bb)\n            return 1;\n        if (aa > bb)\n            return -1;\n        return 0;\n      }\n\n      \n      const readerPerformance = {\"bars\":\"horizontal\",\"chart_type\":\"BarChart\",\"columns\":[\"Model\",\"F1\",\"Speed (passages/sec)\"],\"data\":[{\"F1\":78.21542223321491,\"Model\":\"RoBERTa\",\"Speed\":118.41880460779026},{\"F1\":79.6479775678566,\"Model\":\"MiniLM\",\"Speed\":235.0263836060577},{\"F1\":73.49806294434092,\"Model\":\"BERT base\",\"Speed\":116.99833085428466},{\"F1\":87.35038229973254,\"Model\":\"RoBERTa large\",\"Speed\":43.45399164221017},{\"F1\":82.29388851439239,\"Model\":\"RoBERTa distilled\",\"Speed\":118.88131118898794},{\"F1\":43.34028303155876,\"Model\":\"distilBERT\",\"Speed\":198.4500591997352}],\"description\":\"Performance benchmarks of different Readers that can be used off-the-shelf in Haystack. Some models are geared towards speed, while others are more performance-focused. Accuracy is measured as F1 score and speed as passages/sec (with passages of 384 tokens).  Each Reader is benchmarked using the SQuAD v2.0 development set, which contains 11866 question answer pairs. When tokenized using the BERT tokenizer and split using a sliding window approach, these become 12350 passages that are passed into the model. We set \\u003ci\\u003emax_seq_len=384\\u003c/i\\u003e and \\u003ci\\u003edoc_stride=128\\u003c/i\\u003e. These benchmarking tests are run using an AWS p3.2xlarge instance with a Nvidia V100 GPU with this \\u003ca href='https://github.com/deepset-ai/haystack/blob/master/test/benchmarks/reader.py'\\u003escript\\u003c/a\\u003e. Please note that we are using the FARMReader class rather than the TransformersReader class. Also, the F1 measure that is reported here is in fact calculated on token level, rather than word level as is done in the official SQuAD script.\",\"subtitle\":\"Time and Accuracy Benchmarks\",\"title\":\"Reader Performance\"}\n      const retrieverPerformance = {\"axes\":{\"label\":\"map\",\"time_label\":\"seconds\",\"time_side\":\"top\"},\"bars\":\"horizontal\",\"chart_type\":\"BarChart\",\"columns\":[\"Model\",\"mAP\",\"Index Speed (docs/sec)\",\"Query Speed (queries/sec)\"],\"data\":[{\"index_speed\":81.2504988059173,\"map\":86.5456409043424,\"model\":\"DPR / Elasticsearch\",\"n_docs\":100000,\"query_speed\":6.239008635095737},{\"index_speed\":483.4698964792531,\"map\":56.26106985872818,\"model\":\"BM25 / Elasticsearch\",\"n_docs\":100000,\"query_speed\":132.02605052193084},{\"index_speed\":120.24128813537725,\"map\":82.74686664920834,\"model\":\"Sentence Transformers / Elasticsearch\",\"n_docs\":100000,\"query_speed\":6.358106794217024},{\"index_speed\":93.59054930302146,\"map\":86.54606328368972,\"model\":\"DPR / FAISS (flat)\",\"n_docs\":100000,\"query_speed\":6.700916380795566},{\"index_speed\":83.61910261947709,\"map\":84.33419639513305,\"model\":\"DPR / FAISS (HNSW)\",\"n_docs\":100000,\"query_speed\":40.6580803190388},{\"index_speed\":478.7131568904452,\"map\":56.26106985872818,\"model\":\"BM25 / OpenSearch (flat)\",\"n_docs\":100000,\"query_speed\":120.12526583899732},{\"index_speed\":80.32081169498916,\"map\":86.51945338480733,\"model\":\"DPR / OpenSearch (flat)\",\"n_docs\":100000,\"query_speed\":17.604366772353018},{\"index_speed\":80.45309468360983,\"map\":86.53719331739565,\"model\":\"DPR / OpenSearch (HNSW)\",\"n_docs\":100000,\"query_speed\":17.226750993345046}],\"description\":\"Comparison of the speed and accuracy of different DocumentStore / Retriever combinations on 100k documents. \\u003cb\\u003eIndexing speed\\u003c/b\\u003e (in docs/sec) refers to how quickly Documents can be inserted into a DocumentStore. \\u003cb\\u003eQuerying speed\\u003c/b\\u003e (in queries/sec) refers to the speed at which the system returns relevant Documents when presented with a query.\\n\\nThe dataset used is Wikipedia, split into 100 word passages (from \\u003ca href='https://github.com/facebookresearch/DPR/blob/master/dpr/data/download_data.py'\\u003ehere\\u003c/a\\u003e)). \\n\\nFor querying, we use the Natural Questions development set in combination with the wiki passages. The Document Store is populated with the 100 word passages in which the answer spans occur (i.e. gold passages) as well as a random selection of 100 word passages in which the answer spans do not occur (i.e. negative passages). We take a total of 100k gold and negative passages. Query and document embedding are generated by the \\u003ci\\u003e\\\"facebook/dpr-question_encoder-single-nq-base\\\"\\u003c/i\\u003e and \\u003ci\\u003e\\\"facebook/dpr-ctx_encoder-single-nq-base\\\"\\u003c/i\\u003e models. The retriever returns 10 candidates and both the recall and mAP scores are calculated on these 10.\\n\\nFor FAISS HNSW, we use \\u003ci\\u003en_links=128\\u003c/i\\u003e, \\u003ci\\u003eefSearch=20\\u003c/i\\u003e and \\u003ci\\u003eefConstruction=80\\u003c/i\\u003e. We use a cosine similarity function with BM25 retrievers, and dot product with DPR. Both index and query benchmarks are performed on an AWS P3.2xlarge instance which is accelerated by an Nvidia V100 GPU.\",\"series\":{\"s0\":\"map\",\"s1\":\"time\",\"s2\":\"time\"},\"subtitle\":\"Time and Accuracy Benchmarks\",\"title\":\"Retriever Performance\"}\n      const retrieverAccuracy = {\"axis\":[{\"x\":\"Number of docs\",\"y\":\"mAP\"}],\"chart_type\":\"LineChart\",\"columns\":[\"n_docs\",\"BM25 / Elasticsearch\",\"DPR / Elasticsearch\",\"DPR / FAISS (flat)\",\"DPR / FAISS (HNSW)\",\"BM25 / OpenSearch (flat)\",\"DPR / OpenSearch (flat)\",\"DPR / OpenSearch (HNSW)\",\"Sentence Transformers / Elasticsearch\"],\"data\":[{\"map\":76.49564526892908,\"model\":\"Sentence Transformers / Elasticsearch\",\"n_docs\":500000},{\"map\":80.86137228234092,\"model\":\"DPR / Elasticsearch\",\"n_docs\":500000},{\"map\":90.06638620360428,\"model\":\"Sentence Transformers / Elasticsearch\",\"n_docs\":1000},{\"map\":87.11255142468552,\"model\":\"Sentence Transformers / Elasticsearch\",\"n_docs\":10000},{\"map\":86.5456409043424,\"model\":\"DPR / Elasticsearch\",\"n_docs\":100000},{\"map\":74.2044471297291,\"model\":\"BM25 / Elasticsearch\",\"n_docs\":1000},{\"map\":45.603960228760656,\"model\":\"BM25 / Elasticsearch\",\"n_docs\":500000},{\"map\":56.26106985872818,\"model\":\"BM25 / Elasticsearch\",\"n_docs\":100000},{\"map\":66.32941083712781,\"model\":\"BM25 / Elasticsearch\",\"n_docs\":10000},{\"map\":92.9510532283089,\"model\":\"DPR / Elasticsearch\",\"n_docs\":1000},{\"map\":89.87097014904354,\"model\":\"DPR / Elasticsearch\",\"n_docs\":10000},{\"map\":82.74686664920834,\"model\":\"Sentence Transformers / Elasticsearch\",\"n_docs\":100000},{\"map\":80.86137228234091,\"model\":\"DPR / FAISS (flat)\",\"n_docs\":500000},{\"map\":89.87097014904354,\"model\":\"DPR / FAISS (flat)\",\"n_docs\":10000},{\"map\":92.9510532283089,\"model\":\"DPR / FAISS (flat)\",\"n_docs\":1000},{\"map\":86.54606328368972,\"model\":\"DPR / FAISS (flat)\",\"n_docs\":100000},{\"map\":84.33419639513305,\"model\":\"DPR / FAISS (HNSW)\",\"n_docs\":100000},{\"map\":89.51337675393017,\"model\":\"DPR / FAISS (HNSW)\",\"n_docs\":10000},{\"map\":92.9510532283089,\"model\":\"DPR / FAISS (HNSW)\",\"n_docs\":1000},{\"map\":75.73315903145605,\"model\":\"DPR / FAISS (HNSW)\",\"n_docs\":500000},{\"map\":66.32941083712774,\"model\":\"BM25 / OpenSearch (flat)\",\"n_docs\":10000},{\"map\":89.87097014904354,\"model\":\"DPR / OpenSearch (flat)\",\"n_docs\":10000},{\"map\":56.26106985872818,\"model\":\"BM25 / OpenSearch (flat)\",\"n_docs\":100000},{\"map\":74.2044471297291,\"model\":\"BM25 / OpenSearch (flat)\",\"n_docs\":1000},{\"map\":86.51945338480733,\"model\":\"DPR / OpenSearch (flat)\",\"n_docs\":100000},{\"map\":45.59509026246651,\"model\":\"BM25 / OpenSearch (flat)\",\"n_docs\":500000},{\"map\":80.861372282341,\"model\":\"DPR / OpenSearch (flat)\",\"n_docs\":500000},{\"map\":92.9510532283089,\"model\":\"DPR / OpenSearch (flat)\",\"n_docs\":1000},{\"map\":89.87097014904357,\"model\":\"DPR / OpenSearch (HNSW)\",\"n_docs\":10000},{\"map\":92.9510532283089,\"model\":\"DPR / OpenSearch (HNSW)\",\"n_docs\":1000},{\"map\":86.53719331739565,\"model\":\"DPR / OpenSearch (HNSW)\",\"n_docs\":100000},{\"map\":80.861372282341,\"model\":\"DPR / OpenSearch (HNSW)\",\"n_docs\":500000}],\"description\":\"Here you can see how the mean avg. precision (mAP) of the retriever decays as the number of documents increases. The set up is the same as the above querying benchmark except that a varying number of negative documents are used to fill the document store.\",\"subtitle\":\"mAP at different number of docs\",\"title\":\"Retriever Accuracy\"}\n      const retrieverSpeed = {\"axis\":[{\"x\":\"Number of docs\",\"y\":\"Queries/sec\"}],\"chart_type\":\"LineChart\",\"columns\":[\"n_docs\",\"BM25 / Elasticsearch\",\"BM25 / OpenSearch (flat)\",\"DPR / Elasticsearch\",\"DPR / FAISS (flat)\",\"DPR / FAISS (HNSW)\",\"DPR / OpenSearch (HNSW)\",\"DPR / OpenSearch (HNSW)\",\"Sentence Transformers / Elasticsearch\"],\"data\":[{\"model\":\"Sentence Transformers / Elasticsearch\",\"n_docs\":500000,\"query_speed\":1.4416146543448518},{\"model\":\"DPR / Elasticsearch\",\"n_docs\":500000,\"query_speed\":1.4681488854743858},{\"model\":\"Sentence Transformers / Elasticsearch\",\"n_docs\":1000,\"query_speed\":48.176051675516526},{\"model\":\"Sentence Transformers / Elasticsearch\",\"n_docs\":10000,\"query_speed\":30.0778559137467},{\"model\":\"DPR / Elasticsearch\",\"n_docs\":100000,\"query_speed\":6.239008635095737},{\"model\":\"BM25 / Elasticsearch\",\"n_docs\":1000,\"query_speed\":258.12517634164914},{\"model\":\"BM25 / Elasticsearch\",\"n_docs\":500000,\"query_speed\":67.45949681882962},{\"model\":\"BM25 / Elasticsearch\",\"n_docs\":100000,\"query_speed\":132.02605052193084},{\"model\":\"BM25 / Elasticsearch\",\"n_docs\":10000,\"query_speed\":196.51035140878585},{\"model\":\"DPR / Elasticsearch\",\"n_docs\":1000,\"query_speed\":36.06325436233689},{\"model\":\"DPR / Elasticsearch\",\"n_docs\":10000,\"query_speed\":25.07636705997116},{\"model\":\"Sentence Transformers / Elasticsearch\",\"n_docs\":100000,\"query_speed\":6.358106794217024},{\"model\":\"DPR / FAISS (flat)\",\"n_docs\":500000,\"query_speed\":1.5303310709494675},{\"model\":\"DPR / FAISS (flat)\",\"n_docs\":10000,\"query_speed\":31.06388073640026},{\"model\":\"DPR / FAISS (flat)\",\"n_docs\":1000,\"query_speed\":35.49036694594937},{\"model\":\"DPR / FAISS (flat)\",\"n_docs\":100000,\"query_speed\":6.700916380795566},{\"model\":\"DPR / FAISS (HNSW)\",\"n_docs\":100000,\"query_speed\":40.6580803190388},{\"model\":\"DPR / FAISS (HNSW)\",\"n_docs\":10000,\"query_speed\":50.01305495228924},{\"model\":\"DPR / FAISS (HNSW)\",\"n_docs\":1000,\"query_speed\":41.538171283159},{\"model\":\"DPR / FAISS (HNSW)\",\"n_docs\":500000,\"query_speed\":45.097511850660666},{\"model\":\"BM25 / OpenSearch (flat)\",\"n_docs\":10000,\"query_speed\":173.8232982275283},{\"model\":\"DPR / OpenSearch (flat)\",\"n_docs\":10000,\"query_speed\":30.86623936563611},{\"model\":\"BM25 / OpenSearch (flat)\",\"n_docs\":100000,\"query_speed\":120.12526583899732},{\"model\":\"BM25 / OpenSearch (flat)\",\"n_docs\":1000,\"query_speed\":174.3733594241761},{\"model\":\"DPR / OpenSearch (flat)\",\"n_docs\":100000,\"query_speed\":17.604366772353018},{\"model\":\"BM25 / OpenSearch (flat)\",\"n_docs\":500000,\"query_speed\":67.59304756122785},{\"model\":\"DPR / OpenSearch (flat)\",\"n_docs\":500000,\"query_speed\":12.09249157007648},{\"model\":\"DPR / OpenSearch (flat)\",\"n_docs\":1000,\"query_speed\":35.35562598951788},{\"model\":\"DPR / OpenSearch (HNSW)\",\"n_docs\":10000,\"query_speed\":30.986629506879076},{\"model\":\"DPR / OpenSearch (HNSW)\",\"n_docs\":1000,\"query_speed\":35.67303735213834},{\"model\":\"DPR / OpenSearch (HNSW)\",\"n_docs\":100000,\"query_speed\":17.226750993345046},{\"model\":\"DPR / OpenSearch (HNSW)\",\"n_docs\":500000,\"query_speed\":11.809321812785312}],\"description\":\"Here you can see how the query speed of different Retriever / DocumentStore combinations scale as the number of documents increases. The set up is the same as the above querying benchmark except that a varying number of negative documents are used to fill the document store.\",\"subtitle\":\"Query Speed at different number of docs\",\"title\":\"Retriever Speed\"}\n\n      google.charts.load(\"current\", {\"packages\": [\"corechart\"]});\n      google.charts.setOnLoadCallback(drawCharts);\n\n      function drawCharts() {\n        drawReaderPerformanceChart()\n        drawRetrieverPerformanceChart()\n        drawRetrieverAccuracyChart()\n        drawRetrieverSpeedChart()\n        \n        sortSelectMenu()\n\n        window.addEventListener(\"resize\", () => {\n          drawReaderPerformanceChart()\n          drawRetrieverPerformanceChart()\n          drawRetrieverAccuracyChart()\n          drawRetrieverSpeedChart()\n        })\n      }\n\n      function drawReaderPerformanceChart() {\n        \n        const data = new google.visualization.DataTable();\n        data.addColumn(\"string\", \"Model\");\n        data.addColumn(\"number\", \"F1\");\n        data.addColumn(\"number\", \"Speed (passages/sec)\");\n\n        let dataArr = [];\n        readerPerformance.data.forEach((d) => dataArr.push([d.Model, d.F1, d.Speed]))\n        data.addRows(dataArr);\n\n        \n        const options = {\n          \"width\": \"100%\",\n          \"height\": 400,\n          colors: [\"#22BA99\", \"#63C7CA\", \"#49B0E4\", \"#FBB14B\"],\n          bar: {\n            groupWidth: \"65%\",\n          },\n          bars: readerPerformance.bars,\n          legend: \"bottom\",\n          displayAnnotations: true,\n          annotations: {\n            textStyle: {\n            color: \"#2b2f55\",\n            fontSize: 16,\n            }\n          }\n        };\n\n        \n        const chart = new google.visualization.BarChart(document.getElementById(\"reader-performance\"));\n        chart.draw(data, options);\n    }\n\n      function drawRetrieverPerformanceChart() {\n        \n        const data = new google.visualization.DataTable();\n        data.addColumn(\"string\", \"Model\");\n        data.addColumn(\"number\", \"mAP\");\n        data.addColumn(\"number\", \"Index Speed (docs/sec)\");\n        data.addColumn(\"number\", \"Query Speed (queries/sec)\");\n\n        let dataArr = [];\n        retrieverPerformance.data.forEach((d) => dataArr.push([d.model, d.map, d.index_speed, d.query_speed]))\n        data.addRows(dataArr);\n\n        \n        const options = {\n          \"width\": \"100%\",\n          \"height\": 500,\n          colors: [\"#22BA99\", \"#63C7CA\", \"#49B0E4\", \"#FBB14B\"],\n          bar: {\n            groupWidth: \"65%\",\n          },\n          bars: retrieverPerformance.bars,\n          legend: \"bottom\",\n          displayAnnotations: true,\n          annotations: {\n            textStyle: {\n              color: \"#2b2f55\",\n              fontSize: 16,\n            }\n          }\n        };\n\n        \n        const chart = new google.visualization[retrieverPerformance.chart_type](document.getElementById(\"retriever-performance\"));\n        chart.draw(data, options);\n    }\n\n      function drawRetrieverAccuracyChart() {\n\n        \n        const n_docs = [1000, 10000, 100000, 500000];\n        const dataRetriever = new Array(retrieverAccuracy.columns);\n\n        for (let z = 0; z < n_docs.length; z++) {\n          dataRetriever[z + 1] = new Array(retrieverAccuracy.columns.length);\n          dataRetriever[z + 1][0] = n_docs[z];\n          for (let j = 0; j < retrieverAccuracy.columns.length; j++) {\n            for (let i = 0; i < retrieverAccuracy.data.length; i++) {\n              if (\n                retrieverAccuracy.columns[j] === retrieverAccuracy.data[i].model &&\n                n_docs[z] === retrieverAccuracy.data[i].n_docs\n              )\n                dataRetriever[z + 1][j] = retrieverAccuracy.data[i].map;\n            }\n          }\n        }\n\n\n        \n        const data = new google.visualization.DataTable();\n        dataRetriever[0].forEach((d) => {\n          data.addColumn(\"number\", d);\n        })\n\n        data.addRows(dataRetriever.slice(1));\n\n        \n        const options = {\n          \"width\": \"100%\",\n          \"height\": 500,\n          colors: [\"#22BA99\", \"#FBB14B\", \"#63C7CA\", \"#49B0E4\"],\n          hAxis: {\n            title: retrieverAccuracy.axis[0].x,\n          },\n          vAxis: {\n            title: retrieverAccuracy.axis[0].y,\n          },\n          pointSize: 5,\n          legend: \"bottom\",\n          displayAnnotations: true,\n          annotations: {\n            textStyle: {\n              color: \"#2b2f55\",\n              fontSize: 16,\n            }\n          }\n\n        };\n\n        \n        const chart = new google.visualization[retrieverAccuracy.chart_type](document.getElementById(\"retriever-accuracy\"));\n        chart.draw(data, options);\n    }\n\n      function drawRetrieverSpeedChart() {\n\n        \n        const n_docs = [1000, 10000, 100000, 500000];\n        const dataRetriever = new Array(retrieverSpeed.columns);\n\n        for (let z = 0; z < n_docs.length; z++) {\n          dataRetriever[z + 1] = new Array(retrieverSpeed.columns.length);\n          dataRetriever[z + 1][0] = n_docs[z];\n          for (let j = 0; j < retrieverSpeed.columns.length; j++) {\n            for (let i = 0; i < retrieverSpeed.data.length; i++) {\n              if (\n                retrieverSpeed.columns[j] === retrieverSpeed.data[i].model &&\n                n_docs[z] === retrieverSpeed.data[i].n_docs\n              )\n                dataRetriever[z + 1][j] = retrieverSpeed.data[i].query_speed;\n            }\n          }\n        }\n\n        \n        const data = new google.visualization.DataTable();\n        dataRetriever[0].forEach((d) => {\n          data.addColumn(\"number\", d);\n        })\n\n        data.addRows(dataRetriever.slice(1));\n\n        \n        const options = {\n          \"width\": \"100%\",\n          \"height\": 500,\n          colors: [\"#22BA99\", \"#63C7CA\", \"#49B0E4\", \"#FBB14B\"],\n          hAxis: {\n            title: retrieverSpeed.axis[0].x,\n          },\n          vAxis: {\n            title: retrieverSpeed.axis[0].y,\n          },\n          pointSize: 5,\n          legend: \"bottom\",\n          displayAnnotations: true,\n          annotations: {\n            textStyle: {\n              color: \"#2b2f55\",\n              fontSize: 16,\n            }\n          }\n        };\n\n        \n        const chart = new google.visualization[retrieverSpeed.chart_type](document.getElementById(\"retriever-speed\"));\n        chart.draw(data, options);\n    }\n  \n\n\n    \n    \n\n\n\n\n\n\n  \n\n\n\n  \n    \n      \n      \n        \n          \n          \n            Community\n            \n              GitHub Discussions\n            \n\n            \n              Discord\n            \n            \n              Hugging Face\n            \n            \n              Open NLP Meetup\n            \n          \n\n          \n          \n            Resources\n            \n              Models\n            \n            \n              Datasets\n            \n          \n\n          \n          \n            Company\n            \n              About\n            \n            \n              Jobs\n            \n          \n        \n\n        \n          \n            \n              \n              \n            \n          \n\n          Sign up for community updates\n\n          \n            \n            \n\n\n  \n    \n      \n        \n      \n      \n        Submit\n      \n      \n        \n      \n    \n  \n\n\n            Thanks! You'll soon receive a confirmation email \ud83d\udce7\n          \n          By submitting my email, I agree to allow deepset to store and process my personal data.\n        \n      \n\n      \n      \n        \n        \n          \n            \n            \n          \n        \n\n        \n        \n          Building a semantic layer for the modern tech stack \u2014 driven by the\n          latest NLP and open source.\n        \n\n        \n        \n          \n          \n            \n              \n                \n              \n            \n          \n\n          \n          \n            \n                \n              \n            \n          \n\n          \n          \n            \n                \n              \n            \n          \n\n          \n          \n            \n                \n              \n            \n          \n\n          \n          \n            \n              \n                \n                  \n                \n              \n            \n          \n        \n\n        \n        \n          \n            Privacy\n          \n\n          \n            Imprint\n          \n        \n\n        \u00a9 2022 deepset GmbH. All rights reserved.\n      \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\nQuery Speed (queries/sec)", "content_type": "text", "score": null, "meta": {"url": "https://haystack.deepset.ai/benchmarks", "base_url": "https://haystack.deepset.ai"}, "id_hash_keys": ["content"], "embedding": null, "id": "fe7d040aae01c4eaaa3d46cdda042987"}